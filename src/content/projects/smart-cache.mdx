---
title: "Smart cache"
description: "Pipeline de Datos y API con CachÃ© Inteligente."
date: "2025-10-10"
tags: ["FastApi", "Azure", "Docker", "Python", "SQL", "Redis"]
---

![Classifier Banner](../../../public/images/smart-cache-low.gif)

<br />
<br />

# Objetivo General

Desarrollar una soluciÃ³n integral de backend que demuestre la capacidad de migrar datos a gran escala, exponerlos a travÃ©s de una API segura y optimizada, y desplegarla en un entorno de nube productivo. El proyecto culmina con la implementaciÃ³n de un sistema de monitoreo y una estrategia de cachÃ© con invalidaciÃ³n automÃ¡tica.

<br />
<br />

# Fase 1: PreparaciÃ³n y MigraciÃ³n de Datos

El primer paso es construir la base de datos en la nube que alimentarÃ¡ nuestra
aplicaciÃ³n.
**SelecciÃ³n del Dataset:**
Para el desarrollo de este proyecto seleccione el dataset **Spotify Tracks DB** - el cual puedes encontrar en el siguiente link:

<br />- [ğŸ”— Spotify Tracks
DB](https://www.kaggle.com/datasets/zaheenhamidani/ultimate-spotify-tracks-db)
este cuenta com mas de 200mil registros, lo que no servira para las pruebas de
tiempo.
<br />

**MigraciÃ³n de Datos con Azure Data Factory:** <br/>
UtilizandoÂ  **Azure Data Factory** para crear un pipeline que extraiga los datos del dataset seleccionado (previamente
subido a un Azure Blob Storage como un archivo .csv). Transforma y carga î‚ETLî‚‚ estos
datos en una tabla especÃ­fica dentro de una base de datos provisionada enÂ  **Azure**
Â (puede serÂ  **Azure SQL** Â oÂ  **Azure Database for PostgreSQL** , como se vio en
los videos).

<br />
<br />

# Fase 2: Desarrollo de API y AutenticaciÃ³n

Con los datos en la nube, crearÃ¡s una API para interactuar con ellos, aplicando
buenas prÃ¡cticas de desarrollo y seguridad.
î²î‚” **TecnologÃ­a:**
Se recomienda desarrollar la API utilizandoÂ  **FastAPI** Â î‚Py thon). Sin
embargo, tienes la libertad de usar otro lenguaje o framework con el que
te sientas mÃ¡s cÃ³modo.
î³î‚” **AutenticaciÃ³n y AutorizaciÃ³n con Firebase:**
ImplementaÂ  **Firebase Authentication** Â para gestionar el registro e inicio de
sesiÃ³n de usuarios.
La API debe estar protegida, y el acceso a ciertos endpoints dependerÃ¡ de
un token JWT vÃ¡lido generado por Firebase.
La lÃ³gica de autorizaciÃ³n es flexible, pero se sugiere replicar el modelo
visto en clase:
En tu tabla deÂ UsersÂ en la base de datos, incluye campos booleanos
comoÂ is_activeÂ yÂ is_adminÂ para determinar los permisos de un usuario.
î´î‚” **Endpoints Requeridos:**
POST /signupî‚’ Para el registro de nuevos usuarios en Firebase y en tu base
de datos.
POST /loginî‚’ Para autenticar a un usuario y obtener su token de acceso.
GET /catalogî‚’ Est e endpoint tendrÃ¡ un comportamiento dual:
Si se llamaÂ  **sin query strings** , debe retornar todos los registros del
catÃ¡logo.
Si se llamaÂ  **con un query string** Â (ej:Â /catalog?category=A), debe retornar
solo la secciÃ³n de datos que coincida con el filtro.
El diseÃ±o exacto del catÃ¡logo y si requiere autenticaciÃ³n de usuario o
de administrador queda a tu discreciÃ³n.

<br />
<br />

# Fase 3: Monitoreo de Rendimiento

Para entender cÃ³mo se comporta tu API bajo carga, la integrarÃ¡s con los servicios
de monitoreo de Azure.
î²î‚” **ConfiguraciÃ³n de Application Insights:**
Integra tu API conÂ  **Azure Application Insights** Â para capturar telemetrÃ­a,
trazas de solicitudes, tiempos de respuesta y posibles errores.
î³î‚” **Pruebas de Carga:**
Realiza mÃºltiples llamadas (requests) consecutivas a tu endpointÂ GET
/catalog.
Analiza el panel de Application Insights para observar el comportamiento
de la APIî‚’ identifica los tiempos promedio de respuesta, el nÃºmero de
solicitudes por segundo y cualquier cuello de botella.

<br />
<br />

# Fase 4: ImplementaciÃ³n de CachÃ© con Redis (El Reto)

Para mejorar drÃ¡sticamente los tiempos de respuesta, implementarÃ¡s una capa de
cachÃ©.
î²î‚” **IntegraciÃ³n con Redis:**
Configura y conecta una base de datos deÂ  **Redis** Â a tu API.
î³î‚” **Persistencia en CachÃ© y Reto de Llaves DinÃ¡micas:**
Modifica el endpointÂ GET /catalogÂ para que, antes de consultar la base de
datos, primero verifique si la respuesta ya existe en Redis.
LaÂ  **llave (key)** Â utilizada para guardar cada respuesta en Redis debe
generarse dinÃ¡micamente a partir de losÂ  **query strings** Â de la peticiÃ³n. Por
ejemplo, una peticiÃ³n aÂ /catalog?category=AÂ generarÃ¡ una llave
comoÂ catalog:category=A.
Si la llave existe en Redis, la respuesta se devuelve inmediatamente
(cache hit).
Si no existe, se consulta la base de datos, se almacena la respuesta en
Redis usando la llave dinÃ¡mica y luego se devuelve al usuario (cache
miss).

<br />
<br />

# Fase 5: InvalidaciÃ³n de CachÃ©

El cachÃ© debe ser inteligente. Si los datos originales cambian, el cachÃ© obsoleto
debe ser eliminado.
î²î‚” **Endpoint de CreaciÃ³n:**
Implementa un endpointÂ POSTÂ (ej:Â /catalog) que permita agregar un nuevo
registro a la tabla principal. Este endpoint debe estar protegido (por
ejemplo, solo para administradores).
î³î‚” **LÃ³gica de InvalidaciÃ³n:**
DespuÃ©s de agregar el nuevo registro a la base de datos, el sistema debe
identificar a quÃ© categorÃ­a o filtro pertenece este nuevo dato.
A continuaciÃ³n, debesÂ  **eliminar la llave especÃ­fica en Redis** Â que
corresponde a esa categorÃ­a.
î´î‚” **VerificaciÃ³n del Flujo:
Paso 1î‚’** Â Realiza una peticiÃ³nÂ GETÂ con un query string (ej:Â ?category=C). La
primera vez serÃ¡ lenta, la segunda serÃ¡ rÃ¡pida.
**Paso 2î‚’** Â Usa el endpointÂ POSTÂ para agregar un nuevo Ã­tem que pertenezca
a laÂ category=C. La lÃ³gica de invalidaciÃ³n deberÃ¡ borrar la
llaveÂ catalog:category=CÂ de Redis.
**Paso 3î‚’** Â Vuelve a realizar la misma peticiÃ³nÂ GETÂ del Paso 1. Esta
vez,Â  **deberÃ¡ ser lenta de nuevo** , ya que el cachÃ© fue invalidado.

<br />
<br />

# Fase 6: Despliegue en la Nube con Docker ğŸ³

Finalmente, toda la aplicaciÃ³n debe ser empaquetada y desplegada para
funcionar en un entorno de nube real.
î²î‚” **ContainerizaciÃ³n:**
Crea unÂ DockerfileÂ para tu aplicaciÃ³n de API, asegurÃ¡ndote de que incluya
todas las dependencias y configuraciones necesarias para ejecutarse de
forma aislada.
î³î‚” **Release en la Nube:**

Publica la imagen de Docker en un registro de contenedores (como Azure
Container Registry o Docker Hub).
Despliega el contenedor en un servicio de Azure comoÂ  **Azure App
Service** Â oÂ  **Azure Container Apps** Â para que la API sea accesible
pÃºblicamente.

<br />
<br />

<br />- [ğŸ”— Enlace de la
API](https://api-cache-hfeva3d2bfcbehhu.eastus-01.azurewebsites.net/)

<br />- [ğŸ”— Enlace del Repositorio en
GitHub](https://github.com/ricjpg/pipeline-cache)
